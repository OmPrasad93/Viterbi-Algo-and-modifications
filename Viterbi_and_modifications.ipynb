{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk, re, pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint, time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Pierre', 'NOUN'),\n",
       "  ('Vinken', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('61', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('old', 'ADJ'),\n",
       "  (',', '.'),\n",
       "  ('will', 'VERB'),\n",
       "  ('join', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('board', 'NOUN'),\n",
       "  ('as', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('nonexecutive', 'ADJ'),\n",
       "  ('director', 'NOUN'),\n",
       "  ('Nov.', 'NOUN'),\n",
       "  ('29', 'NUM'),\n",
       "  ('.', '.')],\n",
       " [('Mr.', 'NOUN'),\n",
       "  ('Vinken', 'NOUN'),\n",
       "  ('is', 'VERB'),\n",
       "  ('chairman', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Elsevier', 'NOUN'),\n",
       "  ('N.V.', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('the', 'DET'),\n",
       "  ('Dutch', 'NOUN'),\n",
       "  ('publishing', 'VERB'),\n",
       "  ('group', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('Rudolph', 'NOUN'),\n",
       "  ('Agnew', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('55', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('old', 'ADJ'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('former', 'ADJ'),\n",
       "  ('chairman', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Consolidated', 'NOUN'),\n",
       "  ('Gold', 'NOUN'),\n",
       "  ('Fields', 'NOUN'),\n",
       "  ('PLC', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('was', 'VERB'),\n",
       "  ('named', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('a', 'DET'),\n",
       "  ('nonexecutive', 'ADJ'),\n",
       "  ('director', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('this', 'DET'),\n",
       "  ('British', 'ADJ'),\n",
       "  ('industrial', 'ADJ'),\n",
       "  ('conglomerate', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('A', 'DET'),\n",
       "  ('form', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('once', 'ADV'),\n",
       "  ('used', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('*', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('make', 'VERB'),\n",
       "  ('Kent', 'NOUN'),\n",
       "  ('cigarette', 'NOUN'),\n",
       "  ('filters', 'NOUN'),\n",
       "  ('has', 'VERB'),\n",
       "  ('caused', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('high', 'ADJ'),\n",
       "  ('percentage', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('cancer', 'NOUN'),\n",
       "  ('deaths', 'NOUN'),\n",
       "  ('among', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('group', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('workers', 'NOUN'),\n",
       "  ('exposed', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('it', 'PRON'),\n",
       "  ('more', 'ADV'),\n",
       "  ('than', 'ADP'),\n",
       "  ('30', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('ago', 'ADP'),\n",
       "  (',', '.'),\n",
       "  ('researchers', 'NOUN'),\n",
       "  ('reported', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('*T*-1', 'X'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('fiber', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('crocidolite', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('is', 'VERB'),\n",
       "  ('unusually', 'ADV'),\n",
       "  ('resilient', 'ADJ'),\n",
       "  ('once', 'ADP'),\n",
       "  ('it', 'PRON'),\n",
       "  ('enters', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('lungs', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('with', 'ADP'),\n",
       "  ('even', 'ADV'),\n",
       "  ('brief', 'ADJ'),\n",
       "  ('exposures', 'NOUN'),\n",
       "  ('to', 'PRT'),\n",
       "  ('it', 'PRON'),\n",
       "  ('causing', 'VERB'),\n",
       "  ('symptoms', 'NOUN'),\n",
       "  ('that', 'DET'),\n",
       "  ('*T*-1', 'X'),\n",
       "  ('show', 'VERB'),\n",
       "  ('up', 'PRT'),\n",
       "  ('decades', 'NOUN'),\n",
       "  ('later', 'ADJ'),\n",
       "  (',', '.'),\n",
       "  ('researchers', 'NOUN'),\n",
       "  ('said', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('*T*-2', 'X'),\n",
       "  ('.', '.')],\n",
       " [('Lorillard', 'NOUN'),\n",
       "  ('Inc.', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('the', 'DET'),\n",
       "  ('unit', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('New', 'ADJ'),\n",
       "  ('York-based', 'ADJ'),\n",
       "  ('Loews', 'NOUN'),\n",
       "  ('Corp.', 'NOUN'),\n",
       "  ('that', 'DET'),\n",
       "  ('*T*-2', 'X'),\n",
       "  ('makes', 'VERB'),\n",
       "  ('Kent', 'NOUN'),\n",
       "  ('cigarettes', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('stopped', 'VERB'),\n",
       "  ('using', 'VERB'),\n",
       "  ('crocidolite', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('its', 'PRON'),\n",
       "  ('Micronite', 'NOUN'),\n",
       "  ('cigarette', 'NOUN'),\n",
       "  ('filters', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('1956', 'NUM'),\n",
       "  ('.', '.')],\n",
       " [('Although', 'ADP'),\n",
       "  ('preliminary', 'ADJ'),\n",
       "  ('findings', 'NOUN'),\n",
       "  ('were', 'VERB'),\n",
       "  ('reported', 'VERB'),\n",
       "  ('*-2', 'X'),\n",
       "  ('more', 'ADV'),\n",
       "  ('than', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('year', 'NOUN'),\n",
       "  ('ago', 'ADP'),\n",
       "  (',', '.'),\n",
       "  ('the', 'DET'),\n",
       "  ('latest', 'ADJ'),\n",
       "  ('results', 'NOUN'),\n",
       "  ('appear', 'VERB'),\n",
       "  ('in', 'ADP'),\n",
       "  ('today', 'NOUN'),\n",
       "  (\"'s\", 'PRT'),\n",
       "  ('New', 'NOUN'),\n",
       "  ('England', 'NOUN'),\n",
       "  ('Journal', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Medicine', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('a', 'DET'),\n",
       "  ('forum', 'NOUN'),\n",
       "  ('likely', 'ADJ'),\n",
       "  ('*', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('bring', 'VERB'),\n",
       "  ('new', 'ADJ'),\n",
       "  ('attention', 'NOUN'),\n",
       "  ('to', 'PRT'),\n",
       "  ('the', 'DET'),\n",
       "  ('problem', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('A', 'DET'),\n",
       "  ('Lorillard', 'NOUN'),\n",
       "  ('spokewoman', 'NOUN'),\n",
       "  ('said', 'VERB'),\n",
       "  (',', '.'),\n",
       "  ('``', '.'),\n",
       "  ('This', 'DET'),\n",
       "  ('is', 'VERB'),\n",
       "  ('an', 'DET'),\n",
       "  ('old', 'ADJ'),\n",
       "  ('story', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('We', 'PRON'),\n",
       "  (\"'re\", 'VERB'),\n",
       "  ('talking', 'VERB'),\n",
       "  ('about', 'ADP'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('ago', 'ADP'),\n",
       "  ('before', 'ADP'),\n",
       "  ('anyone', 'NOUN'),\n",
       "  ('heard', 'VERB'),\n",
       "  ('of', 'ADP'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('having', 'VERB'),\n",
       "  ('any', 'DET'),\n",
       "  ('questionable', 'ADJ'),\n",
       "  ('properties', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('There', 'DET'),\n",
       "  ('is', 'VERB'),\n",
       "  ('no', 'DET'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('our', 'PRON'),\n",
       "  ('products', 'NOUN'),\n",
       "  ('now', 'ADV'),\n",
       "  ('.', '.'),\n",
       "  (\"''\", '.')]]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the data\n",
    "nltk_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3718\n",
      "196\n",
      "[[('Dan', 'NOUN'), ('E.', 'NOUN'), ('Nelms', 'NOUN'), (',', '.'), ('Valley', 'NOUN'), ('Federal', 'NOUN'), (\"'s\", 'PRT'), ('president', 'NOUN'), ('and', 'CONJ'), ('chief', 'ADJ'), ('executive', 'NOUN'), ('officer', 'NOUN'), (',', '.'), ('said', 'VERB'), ('0', 'X'), ('the', 'DET'), ('one-time', 'ADJ'), ('charge', 'NOUN'), ('substantially', 'ADV'), ('eliminates', 'VERB'), ('future', 'ADJ'), ('losses', 'NOUN'), ('associated', 'VERB'), ('*', 'X'), ('with', 'ADP'), ('the', 'DET'), ('unit', 'NOUN'), ('.', '.')], [('An', 'DET'), ('official', 'NOUN'), ('for', 'ADP'), ('the', 'DET'), ('lead', 'NOUN'), ('underwriter', 'NOUN'), ('declined', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('comment', 'VERB'), ('on', 'ADP'), ('the', 'DET'), ('reason', 'NOUN'), ('for', 'ADP'), ('the', 'DET'), ('delay', 'NOUN'), (',', '.'), ('but', 'CONJ'), ('market', 'NOUN'), ('participants', 'NOUN'), ('speculated', 'VERB'), ('that', 'ADP'), ('a', 'DET'), ('number', 'NOUN'), ('of', 'ADP'), ('factors', 'NOUN'), (',', '.'), ('including', 'VERB'), ('a', 'DET'), ('lack', 'NOUN'), ('of', 'ADP'), ('investor', 'NOUN'), ('interest', 'NOUN'), (',', '.'), ('were', 'VERB'), ('responsible', 'ADJ'), ('.', '.')], [('Not', 'ADV'), ('this', 'DET'), ('year', 'NOUN'), ('.', '.')], [('``', '.'), ('It', 'PRON'), ('*EXP*-1', 'X'), (\"'s\", 'VERB'), ('hard', 'ADJ'), ('*', 'X'), ('to', 'PRT'), ('explain', 'VERB'), ('to', 'PRT'), ('a', 'DET'), ('17-year-old', 'ADJ'), ('why', 'ADV'), ('someone', 'NOUN'), ('0', 'X'), ('they', 'PRON'), ('like', 'VERB'), ('*T*-2', 'X'), ('had', 'VERB'), ('*-3', 'X'), ('to', 'PRT'), ('go', 'VERB'), (',', '.'), (\"''\", '.'), ('says', 'VERB'), ('*T*-4', 'X'), ('Mrs.', 'NOUN'), ('Ward', 'NOUN'), ('.', '.')], [('The', 'DET'), ('plan', 'NOUN'), ('calls', 'VERB'), ('for', 'ADP'), ('*', 'X'), ('closing', 'VERB'), ('at', 'ADP'), ('least', 'ADJ'), ('nine', 'NUM'), ('plants', 'NOUN'), ('and', 'CONJ'), ('eliminating', 'VERB'), ('about', 'ADP'), ('3,600', 'NUM'), ('jobs', 'NOUN'), ('.', '.')], [('CS', 'NOUN'), ('First', 'NOUN'), ('Boston', 'NOUN'), (',', '.'), ('however', 'ADV'), (',', '.'), ('benefits', 'VERB'), ('from', 'ADP'), ('the', 'DET'), ('backing', 'NOUN'), ('of', 'ADP'), ('its', 'PRON'), ('largest', 'ADJ'), ('shareholder', 'NOUN'), (',', '.'), ('Credit', 'NOUN'), ('Suisse', 'NOUN'), (',', '.'), ('Switzerland', 'NOUN'), (\"'s\", 'PRT'), ('third', 'ADJ'), ('largest', 'ADJ'), ('bank', 'NOUN'), ('.', '.')], [('The', 'DET'), ('framers', 'NOUN'), ('hardly', 'ADV'), ('discussed', 'VERB'), ('the', 'DET'), ('appropriations', 'NOUN'), ('clause', 'NOUN'), ('at', 'ADP'), ('the', 'DET'), ('Constitutional', 'NOUN'), ('Convention', 'NOUN'), ('of', 'ADP'), ('1787', 'NUM'), (',', '.'), ('according', 'VERB'), ('to', 'PRT'), ('Madison', 'NOUN'), (\"'s\", 'PRT'), ('notes', 'NOUN'), ('.', '.')], [('Rather', 'ADV'), (',', '.'), ('Japanese', 'ADJ'), ('investment', 'NOUN'), ('will', 'VERB'), ('spur', 'VERB'), ('integration', 'NOUN'), ('of', 'ADP'), ('certain', 'ADJ'), ('sectors', 'NOUN'), (',', '.'), ('says', 'VERB'), ('0', 'X'), ('*T*-1', 'X'), ('Kent', 'NOUN'), ('Calder', 'NOUN'), (',', '.'), ('a', 'DET'), ('specialist', 'NOUN'), ('in', 'ADP'), ('East', 'ADJ'), ('Asian', 'ADJ'), ('economies', 'NOUN'), ('at', 'ADP'), ('the', 'DET'), ('Woodrow', 'NOUN'), ('Wilson', 'NOUN'), ('School', 'NOUN'), ('for', 'ADP'), ('Public', 'NOUN'), ('and', 'CONJ'), ('Internatonal', 'NOUN'), ('Affairs', 'NOUN'), ('at', 'ADP'), ('Princeton', 'NOUN'), ('University', 'NOUN'), ('.', '.')], [('There', 'DET'), ('is', 'VERB'), ('no', 'DET'), ('downside', 'NOUN'), ('if', 'ADP'), ('the', 'DET'), ('president', 'NOUN'), ('asserts', 'VERB'), ('a', 'DET'), ('right', 'NOUN'), ('of', 'ADP'), ('excision', 'NOUN'), ('over', 'ADP'), ('unconstitutional', 'ADJ'), ('conditions', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('fiscal', 'ADJ'), ('1990', 'NUM'), ('appropriations', 'NOUN'), ('bills', 'NOUN'), ('.', '.')], [('About', 'ADP'), ('30', 'NUM'), ('%', 'NOUN'), ('of', 'ADP'), ('Ratners', 'NOUN'), (\"'s\", 'PRT'), ('profit', 'NOUN'), ('already', 'ADV'), ('is', 'VERB'), ('derived', 'VERB'), ('*-1', 'X'), ('from', 'ADP'), ('the', 'DET'), ('U.S.', 'NOUN'), ('.', '.')], [('Most', 'ADV'), ('recently', 'ADV'), (',', '.'), ('Mr.', 'NOUN'), ('Veraldi', 'NOUN'), (',', '.'), ('59', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('has', 'VERB'), ('been', 'VERB'), ('vice', 'NOUN'), ('president', 'NOUN'), ('of', 'ADP'), ('product', 'NOUN'), ('and', 'CONJ'), ('manufacturing', 'VERB'), ('engineering', 'NOUN'), ('at', 'ADP'), ('Ford', 'NOUN'), ('Motor', 'NOUN'), ('Co', 'NOUN'), ('.', '.')], [('The', 'DET'), ('bids', 'NOUN'), (',', '.'), ('he', 'PRON'), ('added', 'VERB'), ('0', 'X'), ('*T*-1', 'X'), (',', '.'), ('were', 'VERB'), ('``', '.'), ('contrary', 'ADJ'), ('to', 'PRT'), ('common', 'ADJ'), ('sense', 'NOUN'), ('.', '.'), (\"''\", '.')], [('Nissan', 'NOUN'), ('Motor', 'NOUN'), ('Co.', 'NOUN'), (',', '.'), ('Japan', 'NOUN'), (\"'s\", 'PRT'), ('second-largest', 'ADJ'), ('car', 'NOUN'), ('maker', 'NOUN'), (',', '.'), ('announced', 'VERB'), ('Wednesday', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('parent', 'NOUN'), ('concern', 'NOUN'), (\"'s\", 'PRT'), ('pretax', 'NOUN'), ('earnings', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('first', 'ADJ'), ('half', 'DET'), ('ended', 'VERB'), ('last', 'ADJ'), ('Sept.', 'NOUN'), ('30', 'NUM'), ('rose', 'VERB'), ('14', 'NUM'), ('%', 'NOUN'), ('to', 'PRT'), ('88.32', 'NUM'), ('billion', 'NUM'), ('yen', 'NOUN'), ('-LRB-', '.'), ('$', '.'), ('618.1', 'NUM'), ('million', 'NUM'), ('*U*', 'X'), ('-RRB-', '.'), ('from', 'ADP'), ('77.6', 'NUM'), ('billion', 'NUM'), ('yen', 'NOUN'), ('a', 'DET'), ('year', 'NOUN'), ('earlier', 'ADJ'), ('.', '.')], [('4', 'X'), ('.', '.'), ('*', 'X'), ('Buy', 'VERB'), ('a', 'DET'), ('diamond', 'NOUN'), ('necklace', 'NOUN'), ('.', '.')], [('Mr.', 'NOUN'), ('Stronach', 'NOUN'), ('will', 'VERB'), ('direct', 'VERB'), ('an', 'DET'), ('effort', 'NOUN'), ('*', 'X'), ('to', 'PRT'), ('reduce', 'VERB'), ('overhead', 'NOUN'), ('and', 'CONJ'), ('curb', 'VERB'), ('capital', 'NOUN'), ('spending', 'NOUN'), ('``', '.'), ('until', 'ADP'), ('a', 'DET'), ('more', 'ADV'), ('satisfactory', 'ADJ'), ('level', 'NOUN'), ('of', 'ADP'), ('profit', 'NOUN'), ('is', 'VERB'), ('achieved', 'VERB'), ('and', 'CONJ'), ('maintained', 'VERB'), ('*-1', 'X'), (',', '.'), (\"''\", '.'), ('Magna', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('*T*-2', 'X'), ('.', '.')], [('The', 'DET'), ('start', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('whole', 'ADJ'), ('process', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('key', 'NOUN'), ('-', '.'), ('someone', 'NOUN'), ('must', 'VERB'), ('fundamentally', 'ADV'), ('increase', 'VERB'), ('or', 'CONJ'), ('decrease', 'VERB'), ('his', 'PRON'), ('ownership', 'NOUN'), ('in', 'ADP'), ('widgets', 'NOUN'), ('*-1', 'X'), ('to', 'PRT'), ('make', 'VERB'), ('widget', 'NOUN'), ('prices', 'NOUN'), ('move', 'VERB'), ('.', '.')], [('The', 'DET'), ('Constitution', 'NOUN'), ('does', 'VERB'), ('not', 'ADV'), ('expressly', 'ADV'), ('give', 'VERB'), ('the', 'DET'), ('president', 'NOUN'), ('such', 'ADJ'), ('power', 'NOUN'), ('.', '.')], [('In', 'ADP'), ('other', 'ADJ'), ('transactions', 'NOUN'), (',', '.'), ('Mr.', 'NOUN'), ('Simmons', 'NOUN'), ('has', 'VERB'), ('followed', 'VERB'), ('friendly', 'ADJ'), ('offers', 'NOUN'), ('with', 'ADP'), ('a', 'DET'), ('hostile', 'NOUN'), ('tender', 'NOUN'), ('offer', 'NOUN'), ('.', '.')], [('Dan', 'NOUN'), ('Droz', 'NOUN'), (',', '.'), ('leader', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('Carnegie-Mellon', 'NOUN'), ('group', 'NOUN'), (',', '.'), ('sees', 'VERB'), ('benefits', 'NOUN'), ('all', 'DET'), ('around', 'ADP'), ('.', '.')], [('The', 'DET'), ('battle', 'NOUN'), ('has', 'VERB'), ('turned', 'VERB'), ('into', 'ADP'), ('a', 'DET'), ('civil', 'ADJ'), ('war', 'NOUN'), ('at', 'ADP'), ('some', 'DET'), ('firms', 'NOUN'), ('and', 'CONJ'), ('organizations', 'NOUN'), (',', '.'), ('*-1', 'X'), ('causing', 'VERB'), ('internal', 'ADJ'), ('contradictions', 'NOUN'), ('and', 'CONJ'), ('pitting', 'VERB'), ('employee', 'NOUN'), ('against', 'ADP'), ('employee', 'NOUN'), ('.', '.')], [('Lead', 'ADJ'), ('underwriters', 'NOUN'), ('for', 'ADP'), ('the', 'DET'), ('issue', 'NOUN'), ('are', 'VERB'), ('Scotia', 'NOUN'), ('McLeod', 'NOUN'), ('Inc.', 'NOUN'), ('and', 'CONJ'), ('RBC', 'NOUN'), ('Dominion', 'NOUN'), ('Securities', 'NOUN'), ('Inc.', 'NOUN'), (',', '.'), ('both', 'DET'), ('Toronto-based', 'ADJ'), ('investment', 'NOUN'), ('dealers', 'NOUN'), ('.', '.')], [('Freeport-McMoRan', 'NOUN'), (',', '.'), ('the', 'DET'), ('parent', 'NOUN'), ('company', 'NOUN'), (',', '.'), ('holds', 'VERB'), ('roughly', 'ADV'), ('80', 'NUM'), ('%', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('units', 'NOUN'), ('outstanding', 'ADJ'), ('.', '.')], [('Weatherly', 'NOUN'), ('Securities', 'NOUN'), ('Corp.', 'NOUN'), (',', '.'), ('New', 'NOUN'), ('York', 'NOUN'), (',', '.'), ('and', 'CONJ'), ('three', 'NUM'), ('of', 'ADP'), ('its', 'PRON'), ('principals', 'NOUN'), ('--', '.'), ('Dell', 'NOUN'), ('Eugene', 'NOUN'), ('Keehn', 'NOUN'), ('and', 'CONJ'), ('William', 'NOUN'), ('Northy', 'NOUN'), ('Prater', 'NOUN'), ('Jr.', 'NOUN'), (',', '.'), ('both', 'DET'), ('of', 'ADP'), ('Mercer', 'NOUN'), ('Island', 'NOUN'), (',', '.'), ('Wash.', 'NOUN'), (',', '.'), ('and', 'CONJ'), ('Thomas', 'NOUN'), ('Albert', 'NOUN'), ('McFall', 'NOUN'), (',', '.'), ('of', 'ADP'), ('Red', 'NOUN'), ('Bank', 'NOUN'), (',', '.'), ('N.J', 'NOUN'), ('.', '.'), ('--', '.'), ('consented', 'VERB'), ('to', 'PRT'), ('a', 'DET'), ('fine', 'NOUN'), ('of', 'ADP'), ('$', '.'), ('20,000', 'NUM'), ('*U*', 'X'), ('.', '.')], [('Separately', 'ADV'), (',', '.'), ('the', 'DET'), ('Federal', 'NOUN'), ('Energy', 'NOUN'), ('Regulatory', 'NOUN'), ('Commission', 'NOUN'), ('turned', 'VERB'), ('down', 'PRT'), ('for', 'ADP'), ('now', 'ADV'), ('a', 'DET'), ('request', 'NOUN'), ('by', 'ADP'), ('Northeast', 'NOUN'), ('seeking', 'VERB'), ('approval', 'NOUN'), ('of', 'ADP'), ('its', 'PRON'), ('possible', 'ADJ'), ('purchase', 'NOUN'), ('of', 'ADP'), ('PS', 'NOUN'), ('of', 'ADP'), ('New', 'NOUN'), ('Hampshire', 'NOUN'), ('.', '.')], [('Triton', 'NOUN'), ('Securities', 'NOUN'), (',', '.'), ('of', 'ADP'), ('Danville', 'NOUN'), (',', '.'), ('Calif.', 'NOUN'), (',', '.'), ('and', 'CONJ'), ('a', 'DET'), ('principal', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('firm', 'NOUN'), (',', '.'), ('Delwin', 'NOUN'), ('George', 'NOUN'), ('Chase', 'NOUN'), (',', '.'), ('also', 'ADV'), ('of', 'ADP'), ('Danville', 'NOUN'), (',', '.'), ('were', 'VERB'), ('jointly', 'ADV'), ('fined', 'VERB'), ('*-1', 'X'), ('$', '.'), ('10,000', 'NUM'), ('*U*', 'X'), ('and', 'CONJ'), ('given', 'VERB'), ('*-1', 'X'), ('30-day', 'ADJ'), ('suspensions', 'NOUN'), ('as', 'ADP'), ('part', 'NOUN'), ('of', 'ADP'), ('a', 'DET'), ('settlement', 'NOUN'), ('.', '.')], [('The', 'DET'), ('Illinois', 'NOUN'), ('Supreme', 'NOUN'), ('Court', 'NOUN'), ('ordered', 'VERB'), ('the', 'DET'), ('commission', 'NOUN'), ('*-1', 'X'), ('to', 'PRT'), ('audit', 'VERB'), ('Commonwealth', 'NOUN'), ('Edison', 'NOUN'), (\"'s\", 'PRT'), ('construction', 'NOUN'), ('expenses', 'NOUN'), ('and', 'CONJ'), ('refund', 'VERB'), ('any', 'DET'), ('unreasonable', 'ADJ'), ('expenses', 'NOUN'), ('.', '.')], [('Also', 'ADV'), (',', '.'), ('Mr.', 'NOUN'), ('Canepa', 'NOUN'), ('received', 'VERB'), ('a', 'DET'), ('two-week', 'ADJ'), ('suspension', 'NOUN'), ('``', '.'), ('in', 'ADP'), ('a', 'DET'), ('principal', 'ADJ'), ('capacity', 'NOUN'), ('.', '.'), (\"''\", '.')], [('A', 'DET'), ('federal', 'ADJ'), ('appeals', 'NOUN'), ('court', 'NOUN'), ('upheld', 'VERB'), ('a', 'DET'), ('lower', 'ADJ'), ('court', 'NOUN'), ('ruling', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('U.S.', 'NOUN'), ('can', 'VERB'), ('bar', 'VERB'), ('the', 'DET'), ('use', 'NOUN'), ('of', 'ADP'), ('federal', 'ADJ'), ('funds', 'NOUN'), ('for', 'ADP'), ('family-planning', 'ADJ'), ('programs', 'NOUN'), ('that', 'DET'), ('*T*-1', 'X'), ('include', 'VERB'), ('abortion-related', 'ADJ'), ('services', 'NOUN'), ('.', '.')], [('Mr.', 'NOUN'), ('Yamamoto', 'NOUN'), ('insisted', 'VERB'), ('that', 'ADP'), ('headquarters', 'NOUN'), ('had', 'VERB'), (\"n't\", 'ADV'), ('approved', 'VERB'), ('the', 'DET'), ('bids', 'NOUN'), (',', '.'), ('and', 'CONJ'), ('that', 'ADP'), ('he', 'PRON'), ('did', 'VERB'), (\"n't\", 'ADV'), ('know', 'VERB'), ('about', 'ADP'), ('most', 'ADJ'), ('of', 'ADP'), ('the', 'DET'), ('cases', 'NOUN'), ('until', 'ADP'), ('Wednesday', 'NOUN'), ('.', '.')], [('``', '.'), ('You', 'PRON'), (\"'ve\", 'VERB'), ('got', 'VERB'), ('two', 'NUM'), ('champions', 'NOUN'), ('sitting', 'VERB'), ('right', 'ADJ'), ('before', 'ADP'), ('you', 'PRON'), (',', '.'), (\"''\", '.'), ('said', 'VERB'), ('*T*-1', 'X'), ('Mr.', 'NOUN'), ('Baum', 'NOUN'), ('.', '.')], [('The', 'DET'), ('deal', 'NOUN'), ('is', 'VERB'), ('chiefly', 'ADV'), ('designed', 'VERB'), ('*-1', 'X'), ('*-3', 'X'), ('to', 'PRT'), ('give', 'VERB'), ('Mitsubishi', 'NOUN'), ('a', 'DET'), ('window', 'NOUN'), ('on', 'ADP'), ('the', 'DET'), ('U.S.', 'NOUN'), ('glass', 'NOUN'), ('industry', 'NOUN'), (',', '.'), ('says', 'VERB'), ('*T*-2', 'X'), ('Ichiro', 'NOUN'), ('Wakui', 'NOUN'), (',', '.'), ('an', 'DET'), ('executive', 'NOUN'), ('in', 'ADP'), ('Mitsubishi', 'NOUN'), (\"'s\", 'PRT'), ('general', 'ADJ'), ('merchandise', 'NOUN'), ('department', 'NOUN'), ('in', 'ADP'), ('New', 'NOUN'), ('York', 'NOUN'), ('.', '.')], [('So', 'ADP'), ('far', 'ADV'), (',', '.'), ('Mrs.', 'NOUN'), ('Hills', 'NOUN'), ('has', 'VERB'), (\"n't\", 'ADV'), ('deemed', 'VERB'), ('any', 'DET'), ('cases', 'NOUN'), ('bad', 'ADJ'), ('enough', 'ADV'), ('*-1', 'X'), ('to', 'PRT'), ('merit', 'VERB'), ('an', 'DET'), ('accelerated', 'VERB'), ('investigation', 'NOUN'), ('under', 'ADP'), ('the', 'DET'), ('so-called', 'ADJ'), ('special', 'ADJ'), ('301', 'NUM'), ('provision', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('act', 'NOUN'), ('.', '.')], [('The', 'DET'), ('PLO', 'NOUN'), ('in', 'ADP'), ('recent', 'ADJ'), ('months', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('trying', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('join', 'VERB'), ('international', 'ADJ'), ('organizations', 'NOUN'), ('but', 'CONJ'), ('failed', 'VERB'), ('earlier', 'ADV'), ('this', 'DET'), ('year', 'NOUN'), ('*-1', 'X'), ('to', 'PRT'), ('win', 'VERB'), ('membership', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('World', 'NOUN'), ('Health', 'NOUN'), ('Organization', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('World', 'NOUN'), ('Tourism', 'NOUN'), ('Organization', 'NOUN'), ('.', '.')], [('Instead', 'ADV'), (',', '.'), ('they', 'PRON'), ('are', 'VERB'), ('trying', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('build', 'VERB'), ('customer', 'NOUN'), ('loyalty', 'NOUN'), ('by', 'ADP'), ('*-2', 'X'), ('bundling', 'VERB'), ('their', 'PRON'), ('services', 'NOUN'), ('into', 'ADP'), ('packages', 'NOUN'), ('and', 'CONJ'), ('targeting', 'VERB'), ('them', 'PRON'), ('to', 'PRT'), ('small', 'ADJ'), ('segments', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('population', 'NOUN'), ('.', '.')], [('FEDERAL', 'NOUN'), ('FUNDS', 'NOUN'), (':', '.'), ('9', 'NUM'), ('1\\\\/2', 'NUM'), ('%', 'NOUN'), ('high', 'ADJ'), (',', '.'), ('8', 'NUM'), ('3\\\\/4', 'NUM'), ('%', 'NOUN'), ('low', 'ADJ'), (',', '.'), ('8', 'NUM'), ('3\\\\/4', 'NUM'), ('%', 'NOUN'), ('near', 'ADP'), ('closing', 'ADJ'), ('bid', 'NOUN'), (',', '.'), ('9', 'NUM'), ('%', 'NOUN'), ('offered', 'VERB'), ('*', 'X'), ('.', '.')], [('And', 'CONJ'), ('many', 'ADJ'), ('emerging', 'VERB'), ('markets', 'NOUN'), ('have', 'VERB'), ('outpaced', 'VERB'), ('more', 'ADV'), ('mature', 'ADJ'), ('markets', 'NOUN'), (',', '.'), ('such', 'ADJ'), ('as', 'ADP'), ('the', 'DET'), ('U.S.', 'NOUN'), ('and', 'CONJ'), ('Japan', 'NOUN'), ('.', '.')], [('All', 'DET'), ('the', 'DET'), ('contracts', 'NOUN'), ('were', 'VERB'), ('for', 'ADP'), ('computer-system-design', 'ADJ'), ('contracts', 'NOUN'), ('and', 'CONJ'), ('involved', 'VERB'), ('no', 'DET'), ('hardware', 'NOUN'), ('or', 'CONJ'), ('software', 'NOUN'), ('.', '.')], [('This', 'DET'), ('phrase', 'NOUN'), ('once', 'ADV'), ('again', 'ADV'), ('is', 'VERB'), ('found', 'VERB'), ('*-49', 'X'), ('throughout', 'ADP'), ('the', 'DET'), ('many', 'ADJ'), ('appropriations', 'NOUN'), ('bills', 'NOUN'), ('now', 'ADV'), ('moving', 'VERB'), ('through', 'ADP'), ('Congress', 'NOUN'), ('.', '.')], [('The', 'DET'), ('market', 'NOUN'), ('is', 'VERB'), ('just', 'ADV'), ('becoming', 'VERB'), ('more', 'ADV'), ('efficient', 'ADJ'), ('.', '.'), (\"''\", '.')], [('Travelers', 'NOUN'), ('Corp.', 'NOUN'), (\"'s\", 'PRT'), ('third-quarter', 'NOUN'), ('net', 'NOUN'), ('income', 'NOUN'), ('rose', 'VERB'), ('11', 'NUM'), ('%', 'NOUN'), (',', '.'), ('even', 'ADV'), ('though', 'ADP'), ('claims', 'NOUN'), ('stemming', 'VERB'), ('from', 'ADP'), ('Hurricane', 'NOUN'), ('Hugo', 'NOUN'), ('reduced', 'VERB'), ('results', 'NOUN'), ('$', '.'), ('40', 'NUM'), ('million', 'NUM'), ('*U*', 'X'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train and test\n",
    "random.seed(1235)\n",
    "train_set, val_set = train_test_split(nltk_data,test_size=0.05)\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(val_set))\n",
    "print(train_set[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95587"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting list of tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dan',\n",
       " 'E.',\n",
       " 'Nelms',\n",
       " ',',\n",
       " 'Valley',\n",
       " 'Federal',\n",
       " \"'s\",\n",
       " 'president',\n",
       " 'and',\n",
       " 'chief']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokens \n",
    "tokens = [pair[0] for pair in train_tagged_words]\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12079\n"
     ]
    }
   ],
   "source": [
    "# vocabulary\n",
    "V = set(tokens)\n",
    "print(len(V))\n",
    "N_Words=int(len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "{'NOUN', 'ADV', 'PRT', 'NUM', 'CONJ', 'X', 'DET', 'PRON', '.', 'ADJ', 'VERB', 'ADP'}\n"
     ]
    }
   ],
   "source": [
    "# number of tags\n",
    "T = set([pair[1] for pair in train_tagged_words])\n",
    "print(len(T))\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# computing P(w/t) and storing in T x V matrix\n",
    "t = len(T)\n",
    "v = len(V)\n",
    "w_given_t = np.zeros((t, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Congress\n",
      "(0, 2147)\n",
      "(42, 27437)\n",
      "(0, 12844) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing the function\n",
    "print(\"\\n\", \"Congress\")\n",
    "print(word_given_tag('Congress', 'CONJ'))\n",
    "print(word_given_tag('Congress', 'NOUN'))\n",
    "print(word_given_tag('Congress', 'VERB'), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
    "\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351, 27437)\n",
      "(4029, 27437)\n",
      "(70, 12844)\n"
     ]
    }
   ],
   "source": [
    "# examples\n",
    "print(t2_given_t1(t2='DET', t1='NOUN'))\n",
    "print(t2_given_t1('VERB', 'NOUN'))\n",
    "print(t2_given_t1('CONJ', 'VERB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(T), len(T)), dtype='float32')\n",
    "for i, t1 in enumerate(list(T)):\n",
    "    for j, t2 in enumerate(list(T)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/(t2_given_t1(t2, t1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.65116453e-01,   1.72394942e-02,   4.35178764e-02,\n",
       "          9.62204300e-03,   4.23515700e-02,   2.87203416e-02,\n",
       "          1.27929440e-02,   4.77457466e-03,   2.40223050e-01,\n",
       "          1.19546596e-02,   1.46845505e-01,   1.76841497e-01],\n",
       "       [  3.02526597e-02,   8.01196843e-02,   1.46276597e-02,\n",
       "          3.09175532e-02,   6.64893631e-03,   2.29388289e-02,\n",
       "          6.94813803e-02,   1.59574468e-02,   1.35638297e-01,\n",
       "          1.29654258e-01,   3.44414890e-01,   1.19348407e-01],\n",
       "       [  2.46872947e-01,   1.05332453e-02,   1.97498361e-03,\n",
       "          5.92495054e-02,   1.97498361e-03,   1.31665571e-02,\n",
       "          1.00394994e-01,   1.81040149e-02,   4.41079661e-02,\n",
       "          8.55826214e-02,   3.96971703e-01,   2.10664906e-02],\n",
       "       [  3.53827953e-01,   2.95595615e-03,   2.77859885e-02,\n",
       "          1.83564886e-01,   1.38929943e-02,   2.09872887e-01,\n",
       "          3.54714761e-03,   1.18238246e-03,   1.17351465e-01,\n",
       "          3.34023051e-02,   1.80313326e-02,   3.45846899e-02],\n",
       "       [  3.51653457e-01,   5.44946454e-02,   4.65766201e-03,\n",
       "          4.09874246e-02,   4.65766178e-04,   8.84955749e-03,\n",
       "          1.19236141e-01,   5.86865395e-02,   3.49324644e-02,\n",
       "          1.20167673e-01,   1.54168606e-01,   5.17000481e-02],\n",
       "       [  6.18408434e-02,   2.57270690e-02,   1.83285400e-01,\n",
       "          2.87631829e-03,   1.02269100e-02,   7.54234567e-02,\n",
       "          5.54490238e-02,   5.64077981e-02,   1.66027486e-01,\n",
       "          1.70981139e-02,   2.02620640e-01,   1.43016934e-01],\n",
       "       [  6.37835205e-01,   1.17178066e-02,   2.41604255e-04,\n",
       "          2.24691946e-02,   4.83208511e-04,   4.50591929e-02,\n",
       "          5.79850189e-03,   3.38245952e-03,   1.77579131e-02,\n",
       "          2.06692442e-01,   3.95022966e-02,   9.06015933e-03],\n",
       "       [  2.08445296e-01,   3.37811895e-02,   1.26679465e-02,\n",
       "          6.90978905e-03,   4.60652588e-03,   9.25143957e-02,\n",
       "          9.59692895e-03,   8.06142017e-03,   4.03071009e-02,\n",
       "          7.17850253e-02,   4.88675624e-01,   2.26487517e-02],\n",
       "       [  2.22561255e-01,   5.25890701e-02,   2.51278840e-03,\n",
       "          8.05887133e-02,   5.80633581e-02,   2.66535040e-02,\n",
       "          1.73472136e-01,   6.58709481e-02,   9.37808454e-02,\n",
       "          4.46019918e-02,   8.83065611e-02,   9.09090936e-02],\n",
       "       [  6.99327111e-01,   4.75956034e-03,   1.05038565e-02,\n",
       "          2.10077129e-02,   1.73970126e-02,   2.16642041e-02,\n",
       "          4.92368313e-03,   4.92368301e-04,   6.41719997e-02,\n",
       "          6.58132285e-02,   1.23092076e-02,   7.76300654e-02],\n",
       "       [  1.09000310e-01,   8.17502365e-02,   3.12986597e-02,\n",
       "          2.32014954e-02,   5.45001542e-03,   2.17689186e-01,\n",
       "          1.34848952e-01,   3.55808176e-02,   3.48022431e-02,\n",
       "          6.54001832e-02,   1.69417620e-01,   9.15602595e-02],\n",
       "       [  3.22677225e-01,   1.32577782e-02,   1.49684597e-03,\n",
       "          6.31882846e-02,   8.55340506e-04,   3.43205407e-02,\n",
       "          3.23960215e-01,   6.89618289e-02,   3.89179960e-02,\n",
       "          1.07024483e-01,   8.33956990e-03,   1.69998929e-02]], dtype=float32)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(T), index=list(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADV</th>\n",
       "      <th>PRT</th>\n",
       "      <th>NUM</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>X</th>\n",
       "      <th>DET</th>\n",
       "      <th>PRON</th>\n",
       "      <th>.</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>VERB</th>\n",
       "      <th>ADP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.265116</td>\n",
       "      <td>0.017239</td>\n",
       "      <td>0.043518</td>\n",
       "      <td>0.009622</td>\n",
       "      <td>0.042352</td>\n",
       "      <td>0.028720</td>\n",
       "      <td>0.012793</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.240223</td>\n",
       "      <td>0.011955</td>\n",
       "      <td>0.146846</td>\n",
       "      <td>0.176841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.030253</td>\n",
       "      <td>0.080120</td>\n",
       "      <td>0.014628</td>\n",
       "      <td>0.030918</td>\n",
       "      <td>0.006649</td>\n",
       "      <td>0.022939</td>\n",
       "      <td>0.069481</td>\n",
       "      <td>0.015957</td>\n",
       "      <td>0.135638</td>\n",
       "      <td>0.129654</td>\n",
       "      <td>0.344415</td>\n",
       "      <td>0.119348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.246873</td>\n",
       "      <td>0.010533</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>0.059250</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>0.013167</td>\n",
       "      <td>0.100395</td>\n",
       "      <td>0.018104</td>\n",
       "      <td>0.044108</td>\n",
       "      <td>0.085583</td>\n",
       "      <td>0.396972</td>\n",
       "      <td>0.021066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.353828</td>\n",
       "      <td>0.002956</td>\n",
       "      <td>0.027786</td>\n",
       "      <td>0.183565</td>\n",
       "      <td>0.013893</td>\n",
       "      <td>0.209873</td>\n",
       "      <td>0.003547</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.117351</td>\n",
       "      <td>0.033402</td>\n",
       "      <td>0.018031</td>\n",
       "      <td>0.034585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.351653</td>\n",
       "      <td>0.054495</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>0.040987</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.119236</td>\n",
       "      <td>0.058687</td>\n",
       "      <td>0.034932</td>\n",
       "      <td>0.120168</td>\n",
       "      <td>0.154169</td>\n",
       "      <td>0.051700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.061841</td>\n",
       "      <td>0.025727</td>\n",
       "      <td>0.183285</td>\n",
       "      <td>0.002876</td>\n",
       "      <td>0.010227</td>\n",
       "      <td>0.075423</td>\n",
       "      <td>0.055449</td>\n",
       "      <td>0.056408</td>\n",
       "      <td>0.166027</td>\n",
       "      <td>0.017098</td>\n",
       "      <td>0.202621</td>\n",
       "      <td>0.143017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.637835</td>\n",
       "      <td>0.011718</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.022469</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.045059</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.003382</td>\n",
       "      <td>0.017758</td>\n",
       "      <td>0.206692</td>\n",
       "      <td>0.039502</td>\n",
       "      <td>0.009060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.208445</td>\n",
       "      <td>0.033781</td>\n",
       "      <td>0.012668</td>\n",
       "      <td>0.006910</td>\n",
       "      <td>0.004607</td>\n",
       "      <td>0.092514</td>\n",
       "      <td>0.009597</td>\n",
       "      <td>0.008061</td>\n",
       "      <td>0.040307</td>\n",
       "      <td>0.071785</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>0.022649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.222561</td>\n",
       "      <td>0.052589</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.080589</td>\n",
       "      <td>0.058063</td>\n",
       "      <td>0.026654</td>\n",
       "      <td>0.173472</td>\n",
       "      <td>0.065871</td>\n",
       "      <td>0.093781</td>\n",
       "      <td>0.044602</td>\n",
       "      <td>0.088307</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.699327</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>0.010504</td>\n",
       "      <td>0.021008</td>\n",
       "      <td>0.017397</td>\n",
       "      <td>0.021664</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.064172</td>\n",
       "      <td>0.065813</td>\n",
       "      <td>0.012309</td>\n",
       "      <td>0.077630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.109000</td>\n",
       "      <td>0.081750</td>\n",
       "      <td>0.031299</td>\n",
       "      <td>0.023201</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>0.217689</td>\n",
       "      <td>0.134849</td>\n",
       "      <td>0.035581</td>\n",
       "      <td>0.034802</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>0.169418</td>\n",
       "      <td>0.091560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.322677</td>\n",
       "      <td>0.013258</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>0.063188</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.034321</td>\n",
       "      <td>0.323960</td>\n",
       "      <td>0.068962</td>\n",
       "      <td>0.038918</td>\n",
       "      <td>0.107024</td>\n",
       "      <td>0.008340</td>\n",
       "      <td>0.017000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          NOUN       ADV       PRT       NUM      CONJ         X       DET  \\\n",
       "NOUN  0.265116  0.017239  0.043518  0.009622  0.042352  0.028720  0.012793   \n",
       "ADV   0.030253  0.080120  0.014628  0.030918  0.006649  0.022939  0.069481   \n",
       "PRT   0.246873  0.010533  0.001975  0.059250  0.001975  0.013167  0.100395   \n",
       "NUM   0.353828  0.002956  0.027786  0.183565  0.013893  0.209873  0.003547   \n",
       "CONJ  0.351653  0.054495  0.004658  0.040987  0.000466  0.008850  0.119236   \n",
       "X     0.061841  0.025727  0.183285  0.002876  0.010227  0.075423  0.055449   \n",
       "DET   0.637835  0.011718  0.000242  0.022469  0.000483  0.045059  0.005799   \n",
       "PRON  0.208445  0.033781  0.012668  0.006910  0.004607  0.092514  0.009597   \n",
       ".     0.222561  0.052589  0.002513  0.080589  0.058063  0.026654  0.173472   \n",
       "ADJ   0.699327  0.004760  0.010504  0.021008  0.017397  0.021664  0.004924   \n",
       "VERB  0.109000  0.081750  0.031299  0.023201  0.005450  0.217689  0.134849   \n",
       "ADP   0.322677  0.013258  0.001497  0.063188  0.000855  0.034321  0.323960   \n",
       "\n",
       "          PRON         .       ADJ      VERB       ADP  \n",
       "NOUN  0.004775  0.240223  0.011955  0.146846  0.176841  \n",
       "ADV   0.015957  0.135638  0.129654  0.344415  0.119348  \n",
       "PRT   0.018104  0.044108  0.085583  0.396972  0.021066  \n",
       "NUM   0.001182  0.117351  0.033402  0.018031  0.034585  \n",
       "CONJ  0.058687  0.034932  0.120168  0.154169  0.051700  \n",
       "X     0.056408  0.166027  0.017098  0.202621  0.143017  \n",
       "DET   0.003382  0.017758  0.206692  0.039502  0.009060  \n",
       "PRON  0.008061  0.040307  0.071785  0.488676  0.022649  \n",
       ".     0.065871  0.093781  0.044602  0.088307  0.090909  \n",
       "ADJ   0.000492  0.064172  0.065813  0.012309  0.077630  \n",
       "VERB  0.035581  0.034802  0.065400  0.169418  0.091560  \n",
       "ADP   0.068962  0.038918  0.107024  0.008340  0.017000  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    V=[i[0] for i in train_bag]\n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "     \n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]            \n",
    "            state_probability = emission_p * transition_p \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neither',\n",
       " 'Equus',\n",
       " 'nor',\n",
       " 'Tony',\n",
       " 'Lama',\n",
       " 'gave',\n",
       " 'a',\n",
       " 'reason',\n",
       " 'for',\n",
       " 'the',\n",
       " 'changed',\n",
       " 'offer',\n",
       " 'and',\n",
       " 'Tony',\n",
       " 'Lama',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'be',\n",
       " 'reached',\n",
       " '*-1',\n",
       " 'for',\n",
       " 'comment',\n",
       " '.',\n",
       " 'He',\n",
       " 'said',\n",
       " '0',\n",
       " 'Chrysler',\n",
       " 'fully',\n",
       " 'expects',\n",
       " '*-1',\n",
       " 'to',\n",
       " 'have',\n",
       " 'them',\n",
       " 'installed',\n",
       " '*-2',\n",
       " 'across',\n",
       " 'its',\n",
       " 'light-truck',\n",
       " 'line',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Sept.',\n",
       " '1',\n",
       " ',',\n",
       " '1991',\n",
       " ',',\n",
       " 'deadline',\n",
       " '.',\n",
       " 'Mr.',\n",
       " 'Kaminski',\n",
       " ',',\n",
       " 'the',\n",
       " 'schoolteacher',\n",
       " ',',\n",
       " 'and',\n",
       " 'William',\n",
       " 'Mehrens',\n",
       " ',',\n",
       " 'a',\n",
       " 'Michigan',\n",
       " 'State',\n",
       " 'University',\n",
       " 'education',\n",
       " 'professor',\n",
       " ',',\n",
       " 'concluded',\n",
       " 'in',\n",
       " 'a',\n",
       " 'study',\n",
       " 'last',\n",
       " 'June',\n",
       " 'that',\n",
       " 'CAT',\n",
       " 'test',\n",
       " 'versions',\n",
       " 'of',\n",
       " 'Scoring',\n",
       " 'High',\n",
       " 'and',\n",
       " 'Learning',\n",
       " 'Materials',\n",
       " 'should',\n",
       " \"n't\",\n",
       " 'be',\n",
       " 'used',\n",
       " '*-2',\n",
       " 'in',\n",
       " 'the',\n",
       " 'classroom',\n",
       " 'because',\n",
       " 'of',\n",
       " 'their',\n",
       " 'similarity',\n",
       " 'to',\n",
       " 'the',\n",
       " 'actual',\n",
       " 'test',\n",
       " '.',\n",
       " 'But',\n",
       " 'with',\n",
       " 'the',\n",
       " 'index',\n",
       " 'proving',\n",
       " 'somewhat',\n",
       " 'better',\n",
       " 'than',\n",
       " '*',\n",
       " 'expected',\n",
       " 'and',\n",
       " 'the',\n",
       " 'widely',\n",
       " 'anticipated',\n",
       " 'report',\n",
       " 'on',\n",
       " 'October',\n",
       " 'employment',\n",
       " 'scheduled',\n",
       " '*-1',\n",
       " 'to',\n",
       " 'arrive',\n",
       " 'tomorrow',\n",
       " ',',\n",
       " 'stock',\n",
       " 'prices',\n",
       " 'firmed',\n",
       " 'only',\n",
       " 'modestly',\n",
       " 'in',\n",
       " 'response',\n",
       " 'to',\n",
       " 'the',\n",
       " 'report',\n",
       " 'and',\n",
       " 'then',\n",
       " 'faltered',\n",
       " '.',\n",
       " 'Heritage',\n",
       " 'Media',\n",
       " ',',\n",
       " 'which',\n",
       " 'already',\n",
       " '*T*-1',\n",
       " 'owns',\n",
       " 'about',\n",
       " '51',\n",
       " '%',\n",
       " 'of',\n",
       " 'POP',\n",
       " 'Radio',\n",
       " ',',\n",
       " 'proposed',\n",
       " '*-2',\n",
       " 'paying',\n",
       " 'POP',\n",
       " 'Radio',\n",
       " 'shareholders',\n",
       " 'with',\n",
       " 'shares',\n",
       " 'of',\n",
       " 'a',\n",
       " 'new',\n",
       " 'class',\n",
       " 'of',\n",
       " 'Heritage',\n",
       " 'Media',\n",
       " 'preferred',\n",
       " 'stock',\n",
       " 'that',\n",
       " '*T*-122',\n",
       " 'would',\n",
       " 'be',\n",
       " 'convertible',\n",
       " 'into',\n",
       " 'four',\n",
       " 'shares',\n",
       " 'of',\n",
       " 'Heritage',\n",
       " 'Media',\n",
       " \"'s\",\n",
       " 'common',\n",
       " '.']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running on entire test dataset would take more than 3-4hrs. \n",
    "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
    "\n",
    "random.seed(1234)\n",
    "\n",
    "# choose random 5 sents\n",
    "rndom = [random.randint(1,len(val_set)) for x in range(5)]\n",
    "\n",
    "# list of sents\n",
    "val_run = [val_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "val_run_base = [tup for sent in val_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "val_tagged_words = [tup[0] for sent in val_run for tup in sent]\n",
    "val_tagged_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(val_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check = [i for i, j in zip(tagged_seq, val_run_base) if i == j] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9502762430939227"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The validation accuracy comes as below which needs to be improved upon\n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Incorrect cases\n",
    "incorrect_tagged_cases = [[val_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq, val_run_base)) if j[0]!=j[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('somewhat', 'ADV'), (('better', 'ADV'), ('better', 'ADJ'))],\n",
       " [('anticipated', 'VERB'), (('report', 'VERB'), ('report', 'NOUN'))],\n",
       " [('to', 'PRT'), (('arrive', 'NOUN'), ('arrive', 'VERB'))],\n",
       " [('prices', 'NOUN'), (('firmed', 'NOUN'), ('firmed', 'VERB'))],\n",
       " [('then', 'ADV'), (('faltered', 'NOUN'), ('faltered', 'VERB'))],\n",
       " [('Media', 'NOUN'), (('preferred', 'VERB'), ('preferred', 'ADJ'))],\n",
       " [('stock', 'NOUN'), (('that', 'ADP'), ('that', 'DET'))],\n",
       " [('that', 'DET'), (('*T*-122', 'NOUN'), ('*T*-122', 'X'))],\n",
       " [(\"'s\", 'PRT'), (('common', 'ADJ'), ('common', 'NOUN'))]]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "#Modifying the vannila viterbi\n",
    "def Viterbi_unk(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    V=[i[0] for i in train_bag]\n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "     \n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]      \n",
    "            if words[key] in V:\n",
    "                state_probability = emission_p * transition_p\n",
    "            else:\n",
    "                state_probability = transition_p    #Considering only the transition prob as emission will be zero        \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        \n",
    "        state.append(state_max)      \n",
    "    return list(zip(words, state))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq_unk = Viterbi_unk(val_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_unk = [i for i, j in zip(tagged_seq_unk, val_run_base) if i == j] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy after implementing first technique of using only transition probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9558011049723757"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Achieved an accuracy increase of 3% on validation set\n",
    "accuracy = len(check_unk)/len(tagged_seq_unk)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incorrect_tagged_cases_unk = [[val_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq_unk, val_run_base)) if j[0]!=j[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('their', 'PRON'), (('similarity', 'VERB'), ('similarity', 'NOUN'))],\n",
       " [('somewhat', 'ADV'), (('better', 'ADV'), ('better', 'ADJ'))],\n",
       " [('anticipated', 'VERB'), (('report', 'VERB'), ('report', 'NOUN'))],\n",
       " [('prices', 'NOUN'), (('firmed', 'NOUN'), ('firmed', 'VERB'))],\n",
       " [('Media', 'NOUN'), (('preferred', 'VERB'), ('preferred', 'ADJ'))],\n",
       " [('stock', 'NOUN'), (('that', 'ADP'), ('that', 'DET'))],\n",
       " [('that', 'DET'), (('*T*-122', 'DET'), ('*T*-122', 'X'))],\n",
       " [(\"'s\", 'PRT'), (('common', 'ADJ'), ('common', 'NOUN'))]]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_tagged_cases_unk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing another function for technique 2 where we use patterns to replace tags for the unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improvement_func():\n",
    "    \n",
    "    patterns = [(r'^[0-9]+(.[0-9]+)?$', 'NUM'),\n",
    "                       (r'.*ing$', 'VERB'),\n",
    "                       (r'.*ated', 'VERB'),\n",
    "                       (r'.*ers$', 'NOUN'),\n",
    "                       (r'.*ment$', 'NOUN'),\n",
    "                       (r'.*town$', 'NOUN'), \n",
    "                       (r'.*ful$', 'ADJ'),\n",
    "                       (r'.*ous$', 'ADJ'),\n",
    "                       (r'.*ble$', 'ADJ'),                        \n",
    "                       (r'.*','NOUN')]  \n",
    "    regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "    # help(regexp_tagger)\n",
    "    rt=regexp_tagger.tag_sents(val_set[0])\n",
    "    #print(rt)\n",
    "    incorrect_words=[i[1][0] for i in incorrect_tagged_cases_unk]\n",
    "    #print(incorrect_words)\n",
    "    regex_result=regexp_tagger.tag_sents(incorrect_words)\n",
    "    incorrect_words\n",
    "    #regex_result    \n",
    "    for i in incorrect_words[:]:\n",
    "        tagged_seq_unk.remove(i)\n",
    "    for i in regex_result:\n",
    "        tagged_seq_unk.append(i[0])\n",
    "    tagged_seq_unk.sort()\n",
    "    val_run_base.sort()\n",
    "    check_unk = [i for i, j in zip(tagged_seq_unk, val_run_base) if i == j] \n",
    "    accuracy = len(check_unk)/len(tagged_seq_unk)\n",
    "    print(accuracy)\n",
    "    \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9502762430939227"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The validation accuracy for the vanilla viterbi is  as below \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9723756906077348\n"
     ]
    }
   ],
   "source": [
    "#The validation accuracy for the modified code is  as below \n",
    "improvement_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications\n",
    "#### Here incorrect_tag_cases_unknown_mod are the words which are still incorrect after modfication and incorrect_tagged_cases are the words which were incorrect with vanilla viterbi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('somewhat', 'ADV'), (('better', 'ADV'), ('better', 'ADJ'))],\n",
       " [('anticipated', 'VERB'), (('report', 'VERB'), ('report', 'NOUN'))],\n",
       " [('to', 'PRT'), (('arrive', 'NOUN'), ('arrive', 'VERB'))],\n",
       " [('prices', 'NOUN'), (('firmed', 'NOUN'), ('firmed', 'VERB'))],\n",
       " [('then', 'ADV'), (('faltered', 'NOUN'), ('faltered', 'VERB'))],\n",
       " [('Media', 'NOUN'), (('preferred', 'VERB'), ('preferred', 'ADJ'))],\n",
       " [('stock', 'NOUN'), (('that', 'ADP'), ('that', 'DET'))],\n",
       " [('that', 'DET'), (('*T*-122', 'NOUN'), ('*T*-122', 'X'))],\n",
       " [(\"'s\", 'PRT'), (('common', 'ADJ'), ('common', 'NOUN'))]]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('*T*-1', 'X'), (('*T*-122', 'NOUN'), ('*T*-122', 'X'))],\n",
       " [('because', 'ADP'), (('better', 'NOUN'), ('better', 'ADJ'))],\n",
       " [('faltered', 'VERB'), (('firmed', 'NOUN'), ('firmed', 'VERB'))],\n",
       " [('paying', 'VERB'), (('preferred', 'NOUN'), ('preferred', 'ADJ'))],\n",
       " [('that', 'ADP'), (('that', 'NOUN'), ('that', 'DET'))]]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_tag_cases_unknown_mod=[[val_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq_unk, val_run_base)) if j[0]!=j[1]]\n",
    "incorrect_tag_cases_unknown_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
